train_energy.py --dataset iwslt/en-de --selfmode soft --encselfmode soft --temperature 0 --selftemperature 0 --encselftemperature 0 --encselfmode soft --save_to models/de-en/energy/01/default_5_005 --direction deen --train_from models/de-en/10/default_00.e9.pt --yx 1 --xy 0 --eta 0.05
SRC Vocab Size: 39553, TRG Vocab Size: 39553
Building Model
Model(
  (encoder_fx): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (encoder_fy): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (decoder_gx): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (decoder_gy): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (init_x): Sequential(
    (0): Linear(in_features=278, out_features=507, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=507, out_features=278, bias=True)
  )
  (init_y): Sequential(
    (0): Linear(in_features=278, out_features=507, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=507, out_features=278, bias=True)
  )
  (src_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(39553, 278)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1)
    )
  )
  (trg_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(39553, 278)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1)
    )
  )
  (generator_gx): Generator(
    (proj): Linear(in_features=278, out_features=39553, bias=True)
  )
  (generator_gy): Generator(
    (proj): Linear(in_features=278, out_features=39553, bias=True)
  )
)
Loading Model from models/de-en/10/default_00.e9.pt
Namespace(accum_grad=1, anneal_kl=1, anneal_steps=250000, anneal_temperature=0, batch_size=3200, dataset='iwslt/en-de', dependent_posterior=1, direction='deen', dropout=0.1, encselfmode='soft', encselftemperature=0.0, epochs=50, eta=0.05, fix_model_steps=-1, heads=2, learning_rate=0.001, lr_begin=0.00015, lr_end=1e-05, max_src_len=150, max_trg_len=150, mode='soft', residual_var=0, save_to='models/de-en/energy/01/default_5_005', selfdependent_posterior=1, selfmode='soft', selftemperature=0.0, share_decoder_embeddings=1, share_word_embeddings=0, sharelstm=0, temperature=0.0, train_from='models/de-en/10/default_00.e9.pt', unroll=5, xx=1, xy=0, yx=1, yy=1)

Epoch: 0
Training
Epoch Step: 49 lr: 0.000150, PPL yx: 15.116984, Acc yx: 0.464426, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 99 lr: 0.000150, PPL yx: 16.542747, Acc yx: 0.450824, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 149 lr: 0.000150, PPL yx: 16.240977, Acc yx: 0.450854, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 199 lr: 0.000150, PPL yx: 18.932529, Acc yx: 0.423698, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 249 lr: 0.000150, PPL yx: 18.491725, Acc yx: 0.430770, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 299 lr: 0.000150, PPL yx: 16.356097, Acc yx: 0.451854, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 349 lr: 0.000150, PPL yx: 17.449919, Acc yx: 0.440893, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 399 lr: 0.000150, PPL yx: 16.075200, Acc yx: 0.454895, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 449 lr: 0.000150, PPL yx: 17.136487, Acc yx: 0.444085, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 499 lr: 0.000150, PPL yx: 17.936847, Acc yx: 0.435617, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 549 lr: 0.000150, PPL yx: 15.278562, Acc yx: 0.462259, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 599 lr: 0.000150, PPL yx: 15.620848, Acc yx: 0.460250, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 649 lr: 0.000150, PPL yx: 16.368192, Acc yx: 0.451873, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 699 lr: 0.000150, PPL yx: 18.080947, Acc yx: 0.434488, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 749 lr: 0.000150, PPL yx: 15.266937, Acc yx: 0.463269, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 799 lr: 0.000150, PPL yx: 17.571313, Acc yx: 0.439545, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 849 lr: 0.000150, PPL yx: 17.688900, Acc yx: 0.437923, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 899 lr: 0.000149, PPL yx: 16.435317, Acc yx: 0.448760, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 949 lr: 0.000149, PPL yx: 19.055058, Acc yx: 0.421481, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 999 lr: 0.000149, PPL yx: 14.026401, Acc yx: 0.479198, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1049 lr: 0.000149, PPL yx: 17.059900, Acc yx: 0.446359, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1099 lr: 0.000149, PPL yx: 16.469053, Acc yx: 0.450261, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1149 lr: 0.000149, PPL yx: 17.226985, Acc yx: 0.444016, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1199 lr: 0.000149, PPL yx: 16.652461, Acc yx: 0.449252, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1249 lr: 0.000149, PPL yx: 16.873821, Acc yx: 0.448194, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1299 lr: 0.000149, PPL yx: 17.641432, Acc yx: 0.438877, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1349 lr: 0.000149, PPL yx: 19.137259, Acc yx: 0.424947, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1399 lr: 0.000149, PPL yx: 15.614690, Acc yx: 0.457183, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1449 lr: 0.000149, PPL yx: 17.824892, Acc yx: 0.439001, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Validation
Val Result (0): PPL yx: 32.839384, Acc yx: 0.367858. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (1): PPL yx: 32.852708, Acc yx: 0.367642. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (2): PPL yx: 32.871264, Acc yx: 0.367252. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (3): PPL yx: 32.894727, Acc yx: 0.367166. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (4): PPL yx: 32.923019, Acc yx: 0.367426. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (5): PPL yx: 32.831852, Acc yx: 0.367772. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000

Epoch: 1
Training
Epoch Step: 49 lr: 0.000149, PPL yx: 15.492406, Acc yx: 0.462186, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 99 lr: 0.000149, PPL yx: 18.524737, Acc yx: 0.429943, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 149 lr: 0.000149, PPL yx: 16.051265, Acc yx: 0.456624, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 199 lr: 0.000149, PPL yx: 18.323592, Acc yx: 0.429863, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 249 lr: 0.000149, PPL yx: 16.044937, Acc yx: 0.455011, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 299 lr: 0.000149, PPL yx: 17.948183, Acc yx: 0.432294, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 349 lr: 0.000149, PPL yx: 17.359816, Acc yx: 0.440655, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 399 lr: 0.000149, PPL yx: 17.763385, Acc yx: 0.437794, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 449 lr: 0.000149, PPL yx: 14.560801, Acc yx: 0.471214, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 499 lr: 0.000149, PPL yx: 17.494143, Acc yx: 0.439984, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 549 lr: 0.000149, PPL yx: 14.485140, Acc yx: 0.473868, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 599 lr: 0.000149, PPL yx: 17.131677, Acc yx: 0.444091, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 649 lr: 0.000149, PPL yx: 16.613730, Acc yx: 0.448966, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 699 lr: 0.000149, PPL yx: 16.679342, Acc yx: 0.448205, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 749 lr: 0.000149, PPL yx: 17.298339, Acc yx: 0.442794, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 799 lr: 0.000149, PPL yx: 16.859897, Acc yx: 0.446605, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 849 lr: 0.000149, PPL yx: 15.360275, Acc yx: 0.461364, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 899 lr: 0.000149, PPL yx: 16.899841, Acc yx: 0.445116, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 949 lr: 0.000149, PPL yx: 16.222646, Acc yx: 0.451930, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 999 lr: 0.000149, PPL yx: 16.211362, Acc yx: 0.452936, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1049 lr: 0.000149, PPL yx: 19.411441, Acc yx: 0.423147, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1099 lr: 0.000149, PPL yx: 15.887709, Acc yx: 0.456981, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1149 lr: 0.000149, PPL yx: 15.608952, Acc yx: 0.459518, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1199 lr: 0.000149, PPL yx: 17.840564, Acc yx: 0.437382, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1249 lr: 0.000148, PPL yx: 18.208732, Acc yx: 0.431458, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1299 lr: 0.000148, PPL yx: 17.401317, Acc yx: 0.442781, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1349 lr: 0.000148, PPL yx: 15.611569, Acc yx: 0.459273, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1399 lr: 0.000148, PPL yx: 16.876516, Acc yx: 0.445797, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1449 lr: 0.000148, PPL yx: 19.755374, Acc yx: 0.418571, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Validation
Val Result (0): PPL yx: 32.839261, Acc yx: 0.367858. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (1): PPL yx: 32.852397, Acc yx: 0.367599. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (2): PPL yx: 32.870731, Acc yx: 0.367339. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (3): PPL yx: 32.893958, Acc yx: 0.367209. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (4): PPL yx: 32.922000, Acc yx: 0.367382. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (5): PPL yx: 32.831852, Acc yx: 0.367772. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000

Epoch: 2
Training
Epoch Step: 49 lr: 0.000148, PPL yx: 18.141489, Acc yx: 0.432416, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 99 lr: 0.000148, PPL yx: 15.974001, Acc yx: 0.457540, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 149 lr: 0.000148, PPL yx: 17.960929, Acc yx: 0.435575, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 199 lr: 0.000148, PPL yx: 15.705930, Acc yx: 0.458967, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 249 lr: 0.000148, PPL yx: 16.359589, Acc yx: 0.453896, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 299 lr: 0.000148, PPL yx: 17.961210, Acc yx: 0.436043, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 349 lr: 0.000148, PPL yx: 16.208926, Acc yx: 0.451620, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 399 lr: 0.000148, PPL yx: 15.965720, Acc yx: 0.456111, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 449 lr: 0.000148, PPL yx: 17.755252, Acc yx: 0.436435, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 499 lr: 0.000148, PPL yx: 15.556698, Acc yx: 0.460247, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 549 lr: 0.000148, PPL yx: 17.721462, Acc yx: 0.438850, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 599 lr: 0.000148, PPL yx: 17.245857, Acc yx: 0.441880, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 649 lr: 0.000148, PPL yx: 15.580441, Acc yx: 0.459892, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 699 lr: 0.000148, PPL yx: 18.798312, Acc yx: 0.431019, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 749 lr: 0.000148, PPL yx: 15.382783, Acc yx: 0.464183, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 799 lr: 0.000148, PPL yx: 16.922303, Acc yx: 0.444119, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 849 lr: 0.000148, PPL yx: 17.108451, Acc yx: 0.442434, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 899 lr: 0.000148, PPL yx: 16.040469, Acc yx: 0.454998, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 949 lr: 0.000148, PPL yx: 17.304039, Acc yx: 0.443682, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 999 lr: 0.000148, PPL yx: 18.716782, Acc yx: 0.430253, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1049 lr: 0.000148, PPL yx: 15.196774, Acc yx: 0.462802, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1099 lr: 0.000148, PPL yx: 17.756108, Acc yx: 0.434728, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1149 lr: 0.000148, PPL yx: 16.868968, Acc yx: 0.447165, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1199 lr: 0.000148, PPL yx: 17.451212, Acc yx: 0.440285, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1249 lr: 0.000148, PPL yx: 18.103674, Acc yx: 0.432804, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1299 lr: 0.000148, PPL yx: 16.852508, Acc yx: 0.446901, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1349 lr: 0.000148, PPL yx: 17.698482, Acc yx: 0.436688, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1399 lr: 0.000148, PPL yx: 15.723218, Acc yx: 0.458602, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1449 lr: 0.000148, PPL yx: 16.912453, Acc yx: 0.444012, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Validation
Val Result (0): PPL yx: 32.839236, Acc yx: 0.367858. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (1): PPL yx: 32.852338, Acc yx: 0.367599. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (2): PPL yx: 32.870627, Acc yx: 0.367339. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (3): PPL yx: 32.893806, Acc yx: 0.367209. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (4): PPL yx: 32.921799, Acc yx: 0.367382. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (5): PPL yx: 32.831852, Acc yx: 0.367772. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000

Epoch: 3
Training
Epoch Step: 49 lr: 0.000148, PPL yx: 16.245708, Acc yx: 0.450284, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 99 lr: 0.000147, PPL yx: 19.450122, Acc yx: 0.423727, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 149 lr: 0.000147, PPL yx: 16.621607, Acc yx: 0.448379, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 199 lr: 0.000147, PPL yx: 18.293973, Acc yx: 0.429281, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 249 lr: 0.000147, PPL yx: 16.141289, Acc yx: 0.451681, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 299 lr: 0.000147, PPL yx: 16.262041, Acc yx: 0.452673, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 349 lr: 0.000147, PPL yx: 17.596732, Acc yx: 0.436412, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 399 lr: 0.000147, PPL yx: 15.081412, Acc yx: 0.466462, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 449 lr: 0.000147, PPL yx: 18.448521, Acc yx: 0.431472, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 499 lr: 0.000147, PPL yx: 17.205066, Acc yx: 0.442402, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 549 lr: 0.000147, PPL yx: 17.773075, Acc yx: 0.438825, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 599 lr: 0.000147, PPL yx: 17.141721, Acc yx: 0.445288, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 649 lr: 0.000147, PPL yx: 16.310773, Acc yx: 0.451510, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 699 lr: 0.000147, PPL yx: 16.903561, Acc yx: 0.446613, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 749 lr: 0.000147, PPL yx: 16.414163, Acc yx: 0.451534, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 799 lr: 0.000147, PPL yx: 15.494978, Acc yx: 0.460967, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 849 lr: 0.000147, PPL yx: 18.187779, Acc yx: 0.430690, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 899 lr: 0.000147, PPL yx: 16.115003, Acc yx: 0.453314, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
