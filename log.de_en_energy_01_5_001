train_energy.py --dataset iwslt/en-de --selfmode soft --encselfmode soft --temperature 0 --selftemperature 0 --encselftemperature 0 --encselfmode soft --save_to models/de-en/energy/01/default_5_001 --direction deen --train_from models/de-en/10/default_00.e9.pt --yx 1 --xy 0 --eta 0.01
SRC Vocab Size: 39553, TRG Vocab Size: 39553
Building Model
Model(
  (encoder_fx): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (encoder_fy): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (decoder_gx): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (decoder_gy): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=278, out_features=278, bias=True)
            (1): Linear(in_features=278, out_features=278, bias=True)
            (2): Linear(in_features=278, out_features=278, bias=True)
            (3): Linear(in_features=278, out_features=278, bias=True)
          )
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=278, out_features=507, bias=True)
          (w_2): Linear(in_features=507, out_features=278, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (init_x): Sequential(
    (0): Linear(in_features=278, out_features=507, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=507, out_features=278, bias=True)
  )
  (init_y): Sequential(
    (0): Linear(in_features=278, out_features=507, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=507, out_features=278, bias=True)
  )
  (src_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(39553, 278)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1)
    )
  )
  (trg_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(39553, 278)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1)
    )
  )
  (generator_gx): Generator(
    (proj): Linear(in_features=278, out_features=39553, bias=True)
  )
  (generator_gy): Generator(
    (proj): Linear(in_features=278, out_features=39553, bias=True)
  )
)
Loading Model from models/de-en/10/default_00.e9.pt
Namespace(accum_grad=1, anneal_kl=1, anneal_steps=250000, anneal_temperature=0, batch_size=3200, dataset='iwslt/en-de', dependent_posterior=1, direction='deen', dropout=0.1, encselfmode='soft', encselftemperature=0.0, epochs=50, eta=0.01, fix_model_steps=-1, heads=2, learning_rate=0.001, lr_begin=0.00015, lr_end=1e-05, max_src_len=150, max_trg_len=150, mode='soft', residual_var=0, save_to='models/de-en/energy/01/default_5_001', selfdependent_posterior=1, selfmode='soft', selftemperature=0.0, share_decoder_embeddings=1, share_word_embeddings=0, sharelstm=0, temperature=0.0, train_from='models/de-en/10/default_00.e9.pt', unroll=5, xx=1, xy=0, yx=1, yy=1)

Epoch: 0
Training
Epoch Step: 49 lr: 0.000150, PPL yx: 14.767076, Acc yx: 0.468815, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 99 lr: 0.000150, PPL yx: 17.045133, Acc yx: 0.443883, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 149 lr: 0.000150, PPL yx: 17.057280, Acc yx: 0.445117, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 199 lr: 0.000150, PPL yx: 17.553321, Acc yx: 0.437884, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 249 lr: 0.000150, PPL yx: 17.160394, Acc yx: 0.442825, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 299 lr: 0.000150, PPL yx: 16.897912, Acc yx: 0.444462, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 349 lr: 0.000150, PPL yx: 17.709503, Acc yx: 0.438528, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 399 lr: 0.000150, PPL yx: 14.908312, Acc yx: 0.469810, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 449 lr: 0.000150, PPL yx: 16.405678, Acc yx: 0.452060, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 499 lr: 0.000150, PPL yx: 17.834992, Acc yx: 0.437348, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 549 lr: 0.000150, PPL yx: 17.970805, Acc yx: 0.434903, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 599 lr: 0.000150, PPL yx: 16.398271, Acc yx: 0.452741, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 649 lr: 0.000150, PPL yx: 17.358664, Acc yx: 0.439856, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 699 lr: 0.000150, PPL yx: 16.493712, Acc yx: 0.447940, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 749 lr: 0.000150, PPL yx: 17.402699, Acc yx: 0.441245, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 799 lr: 0.000150, PPL yx: 15.383552, Acc yx: 0.461800, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 849 lr: 0.000150, PPL yx: 18.219080, Acc yx: 0.435500, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 899 lr: 0.000149, PPL yx: 15.305647, Acc yx: 0.461908, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 949 lr: 0.000149, PPL yx: 17.287541, Acc yx: 0.442724, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 999 lr: 0.000149, PPL yx: 15.883734, Acc yx: 0.454539, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1049 lr: 0.000149, PPL yx: 17.422021, Acc yx: 0.440252, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1099 lr: 0.000149, PPL yx: 15.993573, Acc yx: 0.455286, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1149 lr: 0.000149, PPL yx: 15.178654, Acc yx: 0.464070, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1199 lr: 0.000149, PPL yx: 15.421793, Acc yx: 0.463183, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1249 lr: 0.000149, PPL yx: 16.266814, Acc yx: 0.451771, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1299 lr: 0.000149, PPL yx: 19.213160, Acc yx: 0.421777, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1349 lr: 0.000149, PPL yx: 17.978228, Acc yx: 0.437385, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1399 lr: 0.000149, PPL yx: 19.316359, Acc yx: 0.422567, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1449 lr: 0.000149, PPL yx: 17.647951, Acc yx: 0.440477, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Validation
Val Result (0): PPL yx: 32.833288, Acc yx: 0.367729. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (1): PPL yx: 32.835529, Acc yx: 0.367685. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (2): PPL yx: 32.838256, Acc yx: 0.367815. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (3): PPL yx: 32.841340, Acc yx: 0.367772. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (4): PPL yx: 32.844690, Acc yx: 0.367729. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (5): PPL yx: 32.831852, Acc yx: 0.367772. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000

Epoch: 1
Training
Epoch Step: 49 lr: 0.000149, PPL yx: 17.136743, Acc yx: 0.443928, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 99 lr: 0.000149, PPL yx: 18.221626, Acc yx: 0.436925, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 149 lr: 0.000149, PPL yx: 16.786894, Acc yx: 0.445764, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 199 lr: 0.000149, PPL yx: 18.215212, Acc yx: 0.432636, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 249 lr: 0.000149, PPL yx: 15.352883, Acc yx: 0.461866, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 299 lr: 0.000149, PPL yx: 17.287857, Acc yx: 0.440851, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 349 lr: 0.000149, PPL yx: 15.887831, Acc yx: 0.454243, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 399 lr: 0.000149, PPL yx: 17.530093, Acc yx: 0.439769, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 449 lr: 0.000149, PPL yx: 18.086594, Acc yx: 0.433930, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 499 lr: 0.000149, PPL yx: 19.025004, Acc yx: 0.425400, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 549 lr: 0.000149, PPL yx: 16.928104, Acc yx: 0.445875, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 599 lr: 0.000149, PPL yx: 17.323163, Acc yx: 0.444801, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 649 lr: 0.000149, PPL yx: 16.468993, Acc yx: 0.449563, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 699 lr: 0.000149, PPL yx: 14.608729, Acc yx: 0.468068, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 749 lr: 0.000149, PPL yx: 17.939562, Acc yx: 0.434342, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 799 lr: 0.000149, PPL yx: 17.732766, Acc yx: 0.438509, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 849 lr: 0.000149, PPL yx: 16.770301, Acc yx: 0.447887, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 899 lr: 0.000149, PPL yx: 17.495037, Acc yx: 0.440890, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 949 lr: 0.000149, PPL yx: 17.710316, Acc yx: 0.437657, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 999 lr: 0.000149, PPL yx: 16.298002, Acc yx: 0.449971, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1049 lr: 0.000149, PPL yx: 17.165818, Acc yx: 0.442075, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1099 lr: 0.000149, PPL yx: 15.139399, Acc yx: 0.466372, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1149 lr: 0.000149, PPL yx: 15.532657, Acc yx: 0.461533, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1199 lr: 0.000149, PPL yx: 16.287982, Acc yx: 0.450803, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1249 lr: 0.000148, PPL yx: 14.909016, Acc yx: 0.467743, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1299 lr: 0.000148, PPL yx: 16.943632, Acc yx: 0.447882, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1349 lr: 0.000148, PPL yx: 15.433726, Acc yx: 0.462080, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1399 lr: 0.000148, PPL yx: 17.012158, Acc yx: 0.443550, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1449 lr: 0.000148, PPL yx: 18.396658, Acc yx: 0.432951, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Validation
Val Result (0): PPL yx: 32.833263, Acc yx: 0.367729. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (1): PPL yx: 32.835470, Acc yx: 0.367685. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (2): PPL yx: 32.838159, Acc yx: 0.367815. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (3): PPL yx: 32.841192, Acc yx: 0.367772. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (4): PPL yx: 32.844494, Acc yx: 0.367729. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (5): PPL yx: 32.831852, Acc yx: 0.367772. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000

Epoch: 2
Training
Epoch Step: 49 lr: 0.000148, PPL yx: 16.159189, Acc yx: 0.451462, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 99 lr: 0.000148, PPL yx: 16.890128, Acc yx: 0.445857, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 149 lr: 0.000148, PPL yx: 15.905897, Acc yx: 0.455333, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 199 lr: 0.000148, PPL yx: 16.273442, Acc yx: 0.453577, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 249 lr: 0.000148, PPL yx: 19.013826, Acc yx: 0.427711, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 299 lr: 0.000148, PPL yx: 15.794991, Acc yx: 0.456931, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 349 lr: 0.000148, PPL yx: 15.157173, Acc yx: 0.466613, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 399 lr: 0.000148, PPL yx: 16.034169, Acc yx: 0.454346, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 449 lr: 0.000148, PPL yx: 16.342850, Acc yx: 0.449701, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 499 lr: 0.000148, PPL yx: 16.497270, Acc yx: 0.450644, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 549 lr: 0.000148, PPL yx: 18.855407, Acc yx: 0.427715, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 599 lr: 0.000148, PPL yx: 16.139073, Acc yx: 0.452279, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 649 lr: 0.000148, PPL yx: 15.771708, Acc yx: 0.460175, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 699 lr: 0.000148, PPL yx: 18.623317, Acc yx: 0.430874, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 749 lr: 0.000148, PPL yx: 19.140568, Acc yx: 0.427608, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 799 lr: 0.000148, PPL yx: 15.038390, Acc yx: 0.463336, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 849 lr: 0.000148, PPL yx: 17.107570, Acc yx: 0.444768, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 899 lr: 0.000148, PPL yx: 16.853791, Acc yx: 0.445810, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 949 lr: 0.000148, PPL yx: 15.570810, Acc yx: 0.460519, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 999 lr: 0.000148, PPL yx: 18.442455, Acc yx: 0.432717, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1049 lr: 0.000148, PPL yx: 17.859806, Acc yx: 0.435482, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1099 lr: 0.000148, PPL yx: 16.905569, Acc yx: 0.446804, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1149 lr: 0.000148, PPL yx: 17.063136, Acc yx: 0.444488, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1199 lr: 0.000148, PPL yx: 17.227580, Acc yx: 0.439991, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1249 lr: 0.000148, PPL yx: 16.944629, Acc yx: 0.444011, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1299 lr: 0.000148, PPL yx: 17.619615, Acc yx: 0.438020, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1349 lr: 0.000148, PPL yx: 16.574311, Acc yx: 0.446994, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1399 lr: 0.000148, PPL yx: 17.289988, Acc yx: 0.442115, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1449 lr: 0.000148, PPL yx: 15.723515, Acc yx: 0.459073, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Validation
Val Result (0): PPL yx: 32.833254, Acc yx: 0.367729. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (1): PPL yx: 32.835443, Acc yx: 0.367685. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (2): PPL yx: 32.838115, Acc yx: 0.367815. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (3): PPL yx: 32.841132, Acc yx: 0.367772. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (4): PPL yx: 32.844416, Acc yx: 0.367729. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000
Val Result (5): PPL yx: 32.831852, Acc yx: 0.367772. PPL xy: 1.000000, Acc xy: 0.000000. PPL xx: 1.000000, Acc xx: 0.000000. PPL yy: 1.000000, Acc yy: 0.000000

Epoch: 3
Training
Epoch Step: 49 lr: 0.000148, PPL yx: 18.194804, Acc yx: 0.435032, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 99 lr: 0.000147, PPL yx: 16.987422, Acc yx: 0.444951, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 149 lr: 0.000147, PPL yx: 19.283535, Acc yx: 0.422531, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 199 lr: 0.000147, PPL yx: 16.526989, Acc yx: 0.447790, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 249 lr: 0.000147, PPL yx: 17.173514, Acc yx: 0.444505, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 299 lr: 0.000147, PPL yx: 19.706316, Acc yx: 0.418155, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 349 lr: 0.000147, PPL yx: 17.468258, Acc yx: 0.441307, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 399 lr: 0.000147, PPL yx: 17.216576, Acc yx: 0.438565, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 449 lr: 0.000147, PPL yx: 15.879726, Acc yx: 0.457083, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 499 lr: 0.000147, PPL yx: 17.103167, Acc yx: 0.441565, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 549 lr: 0.000147, PPL yx: 15.954057, Acc yx: 0.455768, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 599 lr: 0.000147, PPL yx: 15.270074, Acc yx: 0.463714, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 649 lr: 0.000147, PPL yx: 18.508602, Acc yx: 0.430586, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 699 lr: 0.000147, PPL yx: 17.012333, Acc yx: 0.445044, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 749 lr: 0.000147, PPL yx: 17.001477, Acc yx: 0.444913, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 799 lr: 0.000147, PPL yx: 16.418117, Acc yx: 0.452137, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 849 lr: 0.000147, PPL yx: 15.873756, Acc yx: 0.455413, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 899 lr: 0.000147, PPL yx: 16.912395, Acc yx: 0.445281, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 949 lr: 0.000147, PPL yx: 16.596539, Acc yx: 0.449107, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 999 lr: 0.000147, PPL yx: 18.081103, Acc yx: 0.435261, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1049 lr: 0.000147, PPL yx: 15.254487, Acc yx: 0.464943, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1099 lr: 0.000147, PPL yx: 16.273391, Acc yx: 0.452327, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1149 lr: 0.000147, PPL yx: 15.691378, Acc yx: 0.460841, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1199 lr: 0.000147, PPL yx: 14.866727, Acc yx: 0.468262, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1249 lr: 0.000147, PPL yx: 17.086950, Acc yx: 0.444845, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1299 lr: 0.000147, PPL yx: 16.480402, Acc yx: 0.450239, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1349 lr: 0.000147, PPL yx: 17.584995, Acc yx: 0.438291, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
Epoch Step: 1399 lr: 0.000147, PPL yx: 15.472650, Acc yx: 0.461734, PPL xy: 1.000000, Acc xy: 0.000000, PPL xx: 1.000000, Acc xx: 0.000000, PPL yy: 1.000000, Acc yy: 0.000000 , Tokens per Sec: 0.000000
